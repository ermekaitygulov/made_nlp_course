{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2: Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github. Loading special files as well\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./utils.py'):\n",
    "    print(\"utils file not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/homeworks/Lab02_NMT/utils.py -nc\n",
    "\n",
    "if not os.path.exists('./my_network.py'):\n",
    "    print(\"network file not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/homeworks/Lab02_NMT/my_network.py -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "# TODO check torchtext version\n",
    "if torchtext.__version__ == '0.8.1':\n",
    "    from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "WANDB_GLOBAL = dict(\n",
    "    entity='ermekaitygulov',\n",
    "    group='Baseline',\n",
    "    anonymous='allow',\n",
    "    project='NLP-LAB2',\n",
    "    reinit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 5827\n",
      "Unique tokens in target (en) vocabulary: 4233\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 5)\n",
    "TRG.build_vocab(train_data, min_freq = 5)\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEICAYAAACgbaaSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X+YHFW95/H3h4CoCCaYMTfkhxMwsDfwrAFmIS7icgX5pWvw7l1usj4SNBK9wqqr92qCPourZjeuIsIDRgNkQ7yQiCCShWiMUWR9rgEmmhvCL/ODYCaGZPgZryDXhO/+UadJMemZ6Znu6e6a/ryep56pOnWq6nRNn/52nT51ShGBmZmZFctBjS6AmZmZDZwDuJmZWQE5gJuZmRWQA7iZmVkBOYCbmZkVkAO4mZlZATmAW9UkbZN0VgOO2y4pJB1c72Ob1ZukJZK+UsX2/yLp6FqWKe3X9b9BHMCtMBr1QWFWUpT3oKR7JH0knxYRb4iIrY0qU7WKcu7ryQG8RUka0egymA03rXw1aPXnAN6EJH1O0g5Jf5D0mKQzU/qhkr4p6fdp+qakQ9O6iyX9ssd+QtJb0/wSSQslrZT0R+CvJL1O0pWSnpD0vKRfSnpdyj9N0j9Jek7SP0s6o8KyHyRprqQtkp6WdKukI9O6UpPXLEm/k/SUpM/ntn2dpJskPSvpEUmfldSV1n0XmAj839QU+NncYT9Qbn9mtVTuPZh7T8+W9DvgZynv9yU9merVvZKOz+1niaTrJN2d6vh9ko5J6yTpKkm7Je2R9KCkE8qUZZSkuyR1p/pyl6Txad184HTg2lTOa1N6/vPgjZKWpu2fkPQFSQeldRenz4Kvp30/Lum8Cs+R6389RYSnJpqA44DtwFFpuR04Js1/CVgLvBloA/4J+HJadzHwyx77CuCtaX4J8DxwGtkXt9cC1wH3AOOAEcC/Bw5Ny08D56e8707Lbb2UeRtwVpr/ZCrj+LSv7wDLcq8lgOuB1wFvA14C/jKtXwD8AhiVtt8AdJU7TiX78+Sp1lMf78GlwGHA61L6h4HDUx34JrA+t82SVJ9OAQ4GbgaWp3XnAOuAkYCAvwTG5rb7Spp/E/CfgNen43wf+GHuGPcAH+lR9vznwVLgzrRtO/BbYHZadzHwZ+CS9Lnwd8DvAfV3Tlz/6/x+bHQBPPX4h8Bbgd3AWcAhPdZtAc7PLZ8DbEvzF9N/AF+aW3cQ8CLwtjJl+Bzw3R5pq4BZvZQ5X4EfAc7MrRubPgwOzlW48bn19wMz0vxW4Jzcuo9UWIHL7s+Tp1pPfbwHj+5jm5EpzxvT8hLghtz684FH0/y7yILpNOCgHvtZQgrgZY4xFXg2t3wPvQRwsqD8r8CU3LqPAvek+YuBzbl1r0/b/kV/58T1v76Tm9CbTERsBj4FfBHYLWm5pKPS6qOAJ3LZn0hpldqemx9NdhW+pUy+twD/OTWfPyfpOeAdZJWxP28B7sht9wiwDxiTy/Nkbv4F4A1p/qgeZczP96W3/ZnVyyvvVUkjJC1Izch7yAIPZHWupOx7NiJ+BlxL1jq2W9IiSUf0PJik10v6Tmr+3gPcC4xUZX1bRgOHcOBnybhy5YuIF9JsJfXK9b+OHMCbUETcEhHvIKsMAXw1rfp9SiuZmNIA/kj2TRkASX9Rbte5+aeAPwHHlMm3newKfGRuOiwiFlRQ/O3AeT22fW1E7Khg251kTWclE/oov1kj9PYezKf/F2A6WSvaG8muFCFrEu//ABHXRMTJwBTgWOAfymT7DNnPbadGxBHAO3sco6+68hTZVXHPz5JK6mh/XP/ryAG8yUg6TtK7lHVO+xNZM/fLafUy4AuS2iSNBv478I9p3T8Dx0uaKum1ZFfwvYqIl4HFwDckHZWuGt6ejvuPwH+UdE5Kf62kM0qdZPrxbWC+pLek19MmaXqFL/9WYF7qoDMOuKzH+l1Aze9jNRuASt6Dh5P9Fvs02Zfq/1npziX9O0mnSjqE7Ev5n9hf/3se40XgudRJ7IpKyxkR+8jq2nxJh6e6+mn2f5ZUw/W/jhzAm8+hZJ05niJrGnozMC+t+wrQSda540Hg1ymNiPgtWSe3nwKbgFf1SO/F36f9PAA8Q3alf1BEbCe7grgc6Cb7Vv0PVPZ+uRpYAfxE0h/IOrScWsF2pPJ3AY+n13Eb2Qdhyf8i+wLznKS/r3CfZrVUyXtwKVmT9A7gYbI6UKkjyDplPZv28TTwtTL5vknWceuptP8f91h/NfA3qUf3NWW2/69kXxC2kn1W3EL2hb5arv91pPTDv1nTkfR3ZB1S/kOjy2Jm9eX63z9fgVvTkDRW0mnpXtLjyH7nu6PR5TKzoef6P3AeNciayWvI7hudBDwHLAe+1dASmVm9uP4PkJvQzczMCshN6GZmZgXU9E3oo0ePjvb29kYXw6yprVu37qmIaGt0OfriumxWmUrrc9MH8Pb2djo7OxtdDLOmJumJ/nM1luuyWWUqrc9uQjczMysgB3AzM7MCcgA3MzMrIAdwMzOzAnIANzMzKyAHcDMzswLqN4BLWixpt6SNubTvSVqfpm2S1qf0dkkv5tZ9O7fNyZIelLRZ0jWSKno2rpmZmR2okvvAlwDXkj0iD4CI+NvSvKQrgedz+bdExNQy+1kIXALcB6wEzgV+NPAim5mZWb9X4BFxL9mzog+QrqIvBJb1tQ9JY4EjImJtZIOvLwUuGHhxzczMDKofie10YFdEbMqlTZL0G2AP8IWI+H/AOLIHtZd0pbS6aZ97d795ti14Tx1KYmbVcn02qz6Az+TVV987gYkR8bSkk4EfSjp+oDuVNAeYAzBx4sQqi2hmZjb8DLoXuqSDgb8GvldKi4iXIuLpNL8O2AIcC+wAxuc2H5/SyoqIRRHREREdbW1N/XwGMzOzhqjmNrKzgEcj4pWmcUltkkak+aOBycDWiNgJ7JE0Lf1ufhFwZxXHNjMza2mV3Ea2DPgVcJykLkmz06oZHNh57Z3AhnRb2W3AxyKi1AHu48ANwGayK3P3QDczMxukfn8Dj4iZvaRfXCbtduD2XvJ3AicMsHxmZmZWhkdiMzMzKyAHcDMzswJyADdrIZImSPq5pIclPSTpkyn9SEmrJW1Kf0eldKWhjzdL2iDppNy+ZqX8myTNatRrMmtVDuBmrWUv8JmImAJMAy6VNAWYC6yJiMnAmrQMcB7Z3SSTycZmWAhZwAeuAE4FTgGuKAV9M6sPB3CzFhIROyPi12n+D8AjZKMiTgduStluYv9Qx9OBpZFZC4xMQyOfA6yOiGci4llgNdnzDcysThzAzVqUpHbgRLIHDI1J4zUAPAmMSfPjgO25zUrDIPeW3vMYcyR1Surs7u6uafnNWp0DuFkLkvQGsls+PxURe/Lr0gOHohbH8aiKZkOn2rHQhxU/IMFagaRDyIL3zRHxg5S8S9LYiNiZmsh3p/QdwITc5qVhkHcAZ/RIv2coy21mr+YrcLMWkoYyvhF4JCK+kVu1Aij1JJ/F/qGOVwAXpd7o04DnU1P7KuBsSaNS57WzU5qZ1YmvwM1ay2nAB4EH05DHAJcDC4Bb01DJTwAXpnUrgfPJhkB+AfgQQEQ8I+nLwAMp35dywyabWR04gJu1kIj4JaBeVp9ZJn8Al/ayr8XA4tqVzswGwk3oZmZmBeQAbmZmVkAO4GZmZgXkAG5mZlZADuBmZmYF5ABuZmZWQA7gZmZmBeQAbmZmVkAO4GZmZgXkAG5mZlZA/Q6lKmkx8F5gd0SckNK+CFwClB7we3lErEzr5gGzgX3AJyJiVUo/F7gaGAHcEBELavtSzMz289MFbbir5Ap8CXBumfSrImJqmkrBewowAzg+bfMtSSMkjQCuA84DpgAzU14zMzMbhH6vwCPiXkntFe5vOrA8Il4CHpe0GTglrdscEVsBJC1PeR8ecInNzMysqt/AL5O0QdLi9DxggHHA9lyerpTWW3pZkuZI6pTU2d3d3Vs2MzOzljXYAL4QOAaYCuwErqxZiYCIWBQRHRHR0dbWVstdm5mZDQuDeh54ROwqzUu6HrgrLe4AJuSyjk9p9JFuZmZmAzSoK3BJY3OL7wc2pvkVwAxJh0qaBEwG7gceACZLmiTpNWQd3VYMvthmNhjpJ6/dkjbm0r4naX2atklan9LbJb2YW/ft3DYnS3pQ0mZJ10hSI16PWSur5DayZcAZwGhJXcAVwBmSpgIBbAM+ChARD0m6laxz2l7g0ojYl/ZzGbCK7DayxRHxUM1fjZn1ZwlwLbC0lBARf1ual3Ql8Hwu/5aImFpmPwvJbiW9D1hJdtfJj4agvGbWi0p6oc8sk3xjH/nnA/PLpK8kq+hm1iB93VWSrqIvBN7V1z5SC9wREbE2LS8FLsAB3KyuPBKbmZWcDuyKiE25tEmSfiPpF5JOT2njyO4kKen1rhLfUWI2dBzAzaxkJrAst7wTmBgRJwKfBm6RdMRAdug7SsyGzqB6oZvZ8CLpYOCvgZNLaWlAppfS/DpJW4Bjye4gGZ/b3HeVmDWAr8DNDOAs4NGIeKVpXFJbGgYZSUeT3VWyNSJ2AnskTUu/m18E3NmIQpu1MgdwsxaS7ir5FXCcpC5Js9OqGby6+RzgncCGdFvZbcDHIuKZtO7jwA3AZmAL7sBmVnduQjdrIb3cVUJEXFwm7Xbg9l7ydwIn1LRwZjYgvgI3MzMrIAdwMzOzAnIANzMzKyAHcDMzswJyADczMysgB3AzM7MCcgA3MzMrIAdwMzOzAnIANzMzKyAHcDMzswJyADczMysgB3AzM7MCcgA3MzMrIAdwMzOzAuo3gEtaLGm3pI25tK9JelTSBkl3SBqZ0tslvShpfZq+ndvmZEkPStos6RpJGpqXZGZmNvxV8jzwJcC1wNJc2mpgXkTslfRVYB7wubRuS0RMLbOfhcAlwH3ASuBc4EeDLHfDtM+9u6J82xa8Z4hLYjZwkhYD7wV2R8QJKe2LZHWzO2W7PCJWpnXzgNnAPuATEbEqpZ8LXA2MAG6IiAX1fB1mVsEVeETcCzzTI+0nEbE3La4Fxve1D0ljgSMiYm1EBNmXgQsGV2Qzq8ISsi/PPV0VEVPTVAreU4AZwPFpm29JGiFpBHAdcB4wBZiZ8ppZHdXiN/AP8+or6UmSfiPpF5JOT2njgK5cnq6UZmZ1VO4LeR+mA8sj4qWIeBzYDJySps0RsTUi/hVYnvKaWR1VFcAlfR7YC9ycknYCEyPiRODTwC2SjhjEfudI6pTU2d3d3f8GZlaty1KflsWSRqW0ccD2XJ7SF+/e0g/gumw2dAYdwCVdTPZb2gdSszjpm/rTaX4dsAU4FtjBq5vZx6e0siJiUUR0RERHW1vbYItoZpVZCBwDTCX7En5lrXbsumw2dAYVwFMHls8C74uIF3Lpben3MSQdDUwGtkbETmCPpGmp9/lFwJ1Vl97MqhYRuyJiX0S8DFxP1kQO2ZfsCbmspS/evaWbWR1VchvZMuBXwHGSuiTNJuuVfjiwusftYu8ENkhaD9wGfCwiSr+3fRy4gex3tC0UsAe62XCUOpmWvB8o3TK6Apgh6VBJk8i+kN8PPABMljRJ0mvIOrqtqGeZzayC28giYmaZ5Bt7yXs7cHsv6zqBEwZUOjOrqfSF/AxgtKQu4ArgDElTgQC2AR8FiIiHJN0KPEzW1+XSiNiX9nMZsIrsNrLFEfFQnV+KWcur5D5wMxsmBvKFPOWfD8wvk76SbDwHM2sQD6VqZmZWQA7gZmZmBeQAbmZmVkAO4GZmZgXkAG5mZlZADuBmZmYF5ABuZmZWQA7gZmZmBeQAbmZmVkAO4GZmZgXkAG5mZlZADuBmZmYF5ABuZmZWQA7gZmZmBeQAbmZmVkAO4GYtRNJiSbslbcylfU3So5I2SLpD0siU3i7pRUnr0/Tt3DYnS3pQ0mZJ10hSI16PWStzADdrLUuAc3ukrQZOiIh/C/wWmJdbtyUipqbpY7n0hcAlwOQ09dynmQ0xB3CzFhIR9wLP9Ej7SUTsTYtrgfF97UPSWOCIiFgbEQEsBS4YivKaWe8cwM0s78PAj3LLkyT9RtIvJJ2e0sYBXbk8XSnNzOro4EYXwMyag6TPA3uBm1PSTmBiRDwt6WTgh5KOH+A+5wBzACZOnFjL4pq1vIquwHvp+HKkpNWSNqW/o1K6UqeWzalTzEm5bWal/Jskzar9yzGzwZB0MfBe4AOpWZyIeCkink7z64AtwLHADl7dzD4+pR0gIhZFREdEdLS1tQ3hKzBrPZU2oS/hwE4qc4E1ETEZWJOWAc5jf8eWOWSdXZB0JHAFcCpwCnBFKeibWeNIOhf4LPC+iHghl94maUSaP5qsTm+NiJ3AHknTUu/zi4A7G1B0s5ZWUQAv1/EFmA7clOZvYn8nlunA0sisBUamTi/nAKsj4pmIeJas56t7rprVkaRlwK+A4yR1SZoNXAscDqzucbvYO4ENktYDtwEfi4jS58DHgRuAzWRX5vnfzc2sDqr5DXxM+iYO8CQwJs2PA7bn8pU6uPSWfgD/bmY2NCJiZpnkG3vJeztwey/rOoETalg0MxugmnRii4iQFLXYV9rfImARQEdHR832W0/tc+/uN8+2Be+pQ0nMzGw4quY2sl2pabx0X+julL4DmJDLV+rg0lu6mZmZDVA1AXwFUOpJPov9nVhWABel3ujTgOdTU/sq4GxJo1LntbNTmpmZmQ1QRU3oqePLGcBoSV1kvckXALemTjBPABem7CuB88k6t7wAfAggIp6R9GXggZTvS7kOMWZmZjYAFQXwXjq+AJxZJm8Al/ayn8XA4opLZ2ZmZmV5KFUzM7MCcgA3MzMrIAdwMzOzAnIANzMzKyAHcDMzswJyADczMysgPw/czFqWhzy2IvMVuJmZWQE5gJuZmRWQA7iZmVkBOYCbmZkVkAO4WQuRtFjSbkkbc2lHSlotaVP6OyqlS9I1kjZL2iDppNw2s1L+TZJmlTuWmQ0tB3Cz1rIEOLdH2lxgTURMBtakZYDzgMlpmgMshCzgkz2R8FTgFOCKUtA3s/pxADdrIRFxL9DzMb7TgZvS/E3ABbn0pZFZC4yUNBY4B1gdEc9ExLPAag78UmBmQ8wB3MzGRMTONP8kMCbNjwO25/J1pbTe0g8gaY6kTkmd3d3dtS21WYtzADezV0REAFHD/S2KiI6I6Ghra6vVbs0MB3Azg12paZz0d3dK3wFMyOUbn9J6SzezOnIAN7MVQKkn+Szgzlz6Rak3+jTg+dTUvgo4W9Ko1Hnt7JRmZnXksdDNWoikZcAZwGhJXWS9yRcAt0qaDTwBXJiyrwTOBzYDLwAfAoiIZyR9GXgg5ftSRPTsGGdmQ8wB3KyFRMTMXladWSZvAJf2sp/FwOIaFs3MBmjQTeiSjpO0PjftkfQpSV+UtCOXfn5um3lpUIjHJJ1Tm5dgZmbWegZ9BR4RjwFTASSNIOvEcgdZM9tVEfH1fH5JU4AZwPHAUcBPJR0bEfsGWwYzM7NWVatObGcCWyLiiT7yTAeWR8RLEfE42e9qp9To+GZmZi2lVgF8BrAst3xZGjt5cW6IRQ/+YGZmViNVB3BJrwHeB3w/JS0EjiFrXt8JXDnQfXrwBzMzs77V4gr8PODXEbELICJ2RcS+iHgZuJ79zeQe/MHMzKxGahHAZ5JrPi+N6JS8Hyg9tnAFMEPSoZImkT3h6P4aHN/MzKzlVHUfuKTDgHcDH80l/29JU8nGU95WWhcRD0m6FXgY2Atc6h7oZpbXPvfuRhfhAJWUaduC99ShJGavVlUAj4g/Am/qkfbBPvLPB+ZXc0wzMzPzWOhmZmaF5ABuZmZWQA7gZmZmBeSHmTSQO8eYmdlg+QrczMysgBzAzczMCsgB3Mz8eGCzAvJv4GbmxwObFZCvwM2sJz8e2KwAHMDNrKeaPh7YzIaGA7iZvaLWjweWNEdSp6TO7u7umpbVrNU5gJtZXk0fDxwRiyKiIyI62trahrjoZq3FAdzM8vx4YLOCcC90MwP8eGCzonEANzPAjwc2Kxo3oZuZmRWQA7iZmVkBOYCbmZkVkAO4mZlZATmAm5mZFZADuJmZWQFVHcAlbZP0YHrUYGdKO1LSakmb0t9RKV2SrkmPINwg6aRqj29mZtaKanUF/lcRMTUiOtLyXGBNREwG1qRlyIZpnJymOWTjLJuZmdkADVUT+nTgpjR/E3BBLn1pZNYCI3sM1WhmZmYVqEUAD+AnktZJmpPSxkTEzjT/JDAmzVf0CEI/wcjMzKxvtRhK9R0RsUPSm4HVkh7Nr4yIkBQD2WFELAIWAXR0dAxoWzMzs1ZQ9RV4ROxIf3cDd5A9bnBXqWk8/d2dslf0CEIzMzPrW1UBXNJhkg4vzQNnkz1ucAUwK2WbBdyZ5lcAF6Xe6NOA53NN7WZmZlahapvQxwB3SCrt65aI+LGkB4BbJc0GngAuTPlXAucDm4EXgA9VeXwzM7OWVFUAj4itwNvKpD8NnFkmPYBLqzmmmZmZeSQ2MzOzQnIANzPAoyqaFY0DuJnleVRFs4JwADezvnhURbMm5QBuZiUeVdGsQGoxEpuZDQ8eVdGsQHwFbmaAR1U0KxoHcDPzqIpmBeQmdDMDj6poVjgO4GbmURXNCmhYBPD2uXc3ughmZmZ15d/AzczMCsgB3MzMrIAcwM3MzArIAdzMzKyAhkUnNjOzRqq0I+22Be8Z4pJYK/EVuJmZWQE5gJuZmRWQA7iZmVkBOYCbmZkV0KA7sUmaACwlG0M5gEURcbWkLwKXAKWH/14eESvTNvOA2cA+4BMRsaqKsreESjrHuGOMmVnrqaYX+l7gMxHx6/QUo3WSVqd1V0XE1/OZJU0BZgDHA0cBP5V0bETsq6IMZmZmLWnQTegRsTMifp3m/wA8AozrY5PpwPKIeCkiHid7itEpgz2+mZlZK6vJb+CS2oETgftS0mWSNkhaLGlUShsHbM9t1kUvAV/SHEmdkjq7u7vLZTEzM2tpVQdwSW8Abgc+FRF7gIXAMcBUYCdw5UD3GRGLIqIjIjra2tqqLaKZmdmwU9VIbJIOIQveN0fEDwAiYldu/fXAXWlxBzAht/n4lGZV8ihQVi13SjUrnmp6oQu4EXgkIr6RSx8bETvT4vuBjWl+BXCLpG+QdWKbDNw/2OObWU25U6pZwVRzBX4a8EHgQUnrU9rlwExJU8m+xW8DPgoQEQ9JuhV4mOzD4lJXdrPmkL5070zzf5BUcadU4HFJpU6pvxrywpoZUEUAj4hfAiqzamUf28wH5g/2mGY29Hp0Sj2NrFPqRUAn2VX6s2TBfW1us7KdUiXNAeYATJw4cUjLbdZqPBKbmb2i1p1S3SHVbOg4gJsZ0Hun1IjYFxEvA9ezf+wGd0o1azAHcDPrs1NqLlvPTqkzJB0qaRLulGpWd1XdRmZmw4Y7pZoVjAO4mblTqlkBOYCbmdWJny5oteTfwM3MzArIAdzMzKyA3ITeQtx8Z2Y2fPgK3MzMrIAcwM3MzArIAdzMzKyAHMDNzMwKyAHczMysgBzAzczMCsgB3MzMrIB8H7i9iu8VNzMrBgdwM7Mm4i/RVikHcBswf8CYmTWefwM3MzMrIF+Bm5kVjFvBDBpwBS7pXEmPSdosaW69j29mteG6bNZYdb0ClzQCuA54N9AFPCBpRUQ8XM9y2NDzFcLw5rrc/Cqpg+B6WGT1bkI/BdgcEVsBJC0HpgOu9C2o0g+YSvhDqO5cl4eJWn3Z9pf2+qt3AB8HbM8tdwGn9swkaQ4wJy3+i6THgNHAU0NewqFT5PI3fdn11T5XN335+1FJ+d9Sj4LkDMe63KzlggaXrVb1q5/9DIWi/k8rqs9N2YktIhYBi/JpkjojoqNBRapakctf5LKDy99IRarLzVoucNkGa7iXrd6d2HYAE3LL41OamRWL67JZg9U7gD8ATJY0SdJrgBnAijqXwcyq57ps1mB1bUKPiL2SLgNWASOAxRHxUIWbL+o/S1MrcvmLXHZw+WtumNblZi0XuGyDNazLpoioRUHMzMysjjyUqpmZWQE5gJuZmRVQ0wfwog3XKGmCpJ9LeljSQ5I+mdKPlLRa0qb0d1Sjy9oXSSMk/UbSXWl5kqT70v/he6njUlOSNFLSbZIelfSIpLcX6fxL+m/pvbNR0jJJry3S+e9NM9XlZq+nzVr/mrluNVO9kbRY0m5JG3NpZc+TMtekMm6QdFKlx2nqAK79wzWeB0wBZkqa0thS9Wsv8JmImAJMAy5NZZ4LrImIycCatNzMPgk8klv+KnBVRLwVeBaY3ZBSVeZq4McR8W+At5G9jkKcf0njgE8AHRFxAlkHsRkU6/wfoAnrcrPX02atf01Zt5qw3iwBzu2R1tt5Og+YnKY5wMKKjxIRTTsBbwdW5ZbnAfMaXa4BvoY7ycaLfgwYm9LGAo81umx9lHl8eoO9C7gLENmIQQeX+7800wS8EXic1EEzl16I88/+Ec6OJLtL5C7gnKKc/z5eV1PX5Waqp81a/5q5bjVjvQHagY39nSfgO8DMcvn6m5r6CpzywzWOa1BZBkxSO3AicB8wJiJ2plVPAmMaVKxKfBP4LPByWn4T8FxE7E3Lzfx/mAR0A/8nNUHeIOkwCnL+I2IH8HXgd8BO4HlgHcU5/71p2rrchPW0Wetf09atgtSb3s7ToOtGswfwwpL0BuB24FMRsSe/LrKvWU15/56k9wK7I2Jdo8sySAcDJwELI+JE4I/0aNJr8vM/iuyhIJOAo4DDOLApzmqk2eppk9e/pq1bRas3tTpPzR7ACzlco6RDyD4Ubo6IH6TkXZLGpvVjgd2NKl8/TgPeJ2kbsJysGe9qYKSk0sA/zfx/6AK6IuK+tHwb2YdOUc7/WcDjEdEdEX8GfkD2PynK+e9N09XlJq2nzVz/mrluFaHe9HaeBl03mj2AF264RkkCbgQeiYhv5FatAGal+Vlkv7k1nYiYFxHjI6Kd7Hz/LCI+APwc+JuUrZnL/ySwXdJxKelMskdcFuL8kzUBTpP0+vReKpW/EOe/D01Vl5u1njZz/WvyulWEetPbeVoBXJR6o08Dns81tfet3p0NBtER4Hzgt8AW4PONLk8F5X0HWdPIBmB9ms4n+x1rDbAJ+CkwLtBAAAAAnklEQVRwZKPLWsFrOQO4K80fDdwPbAa+Dxza6PL1Ue6pQGf6H/wQGFWk8w/8D+BRYCPwXeDQIp3/Pl5X09TlItTTZqx/zVy3mqneAMvIfov/M1nLxezezhNZJ8XrUr14kKwnfUXH8VCqZmZmBdTsTehmZmZWhgO4mZlZATmAm5mZFZADuJmZWQE5gJuZmRWQA7iZmVkBOYCbmZkV0P8HbHSLo3tXwEYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in test_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in test_data.examples])\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.field.Field at 0x7ff611c56a90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iterator.dataset.fields['trg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">less_hd_2ifqef4p</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ermekaitygulov/NLP-LAB2\" target=\"_blank\">https://wandb.ai/ermekaitygulov/NLP-LAB2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2gai4wi5\" target=\"_blank\">https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2gai4wi5</a><br/>\n",
       "                Run data is saved locally in <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210512_153817-2gai4wi5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f5ae62b5cc0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "train_step = 0\n",
    "val_step = 0\n",
    "best_valid_loss = float('inf')\n",
    "model_name = 'less_hd'\n",
    "model_config = {}\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "name = f'{model_name}_{wandb.util.generate_id()}'\n",
    "if wandb.run:\n",
    "    wandb.finish()\n",
    "wandb.init(name=name, config=model_config, **WANDB_GLOBAL)\n",
    "wandb.watch(model, criterion, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,784,734 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model.apply(init_weights)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:46<00:00, 13.34it/s, train_loss=4.53]\n",
      "100%|██████████| 40/40 [00:00<00:00, 57.52it/s, train_loss=5.28]\n",
      "  0%|          | 1/625 [00:00<01:20,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 47s\n",
      "\tTrain Loss: 5.091 | Train PPL: 162.607\n",
      "\t Val. Loss: 5.194 |  Val. PPL: 180.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:47<00:00, 13.13it/s, train_loss=4.01]\n",
      "100%|██████████| 40/40 [00:00<00:00, 58.31it/s, train_loss=5.28]\n",
      "  0%|          | 2/625 [00:00<00:51, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 48s\n",
      "\tTrain Loss: 4.190 | Train PPL:  65.993\n",
      "\t Val. Loss: 5.100 |  Val. PPL: 163.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:48<00:00, 12.88it/s, train_loss=3.76]\n",
      "100%|██████████| 40/40 [00:00<00:00, 56.91it/s, train_loss=5.23]\n",
      "  0%|          | 1/625 [00:00<01:12,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 49s\n",
      "\tTrain Loss: 3.823 | Train PPL:  45.741\n",
      "\t Val. Loss: 4.894 |  Val. PPL: 133.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:47<00:00, 13.05it/s, train_loss=3.49]\n",
      "100%|██████████| 40/40 [00:00<00:00, 56.87it/s, train_loss=5.16]\n",
      "  0%|          | 1/625 [00:00<01:09,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 48s\n",
      "\tTrain Loss: 3.564 | Train PPL:  35.319\n",
      "\t Val. Loss: 4.791 |  Val. PPL: 120.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:48<00:00, 13.02it/s, train_loss=3.44]\n",
      "100%|██████████| 40/40 [00:00<00:00, 54.31it/s, train_loss=5.13]\n",
      "  0%|          | 2/625 [00:00<00:54, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 48s\n",
      "\tTrain Loss: 3.397 | Train PPL:  29.882\n",
      "\t Val. Loss: 4.715 |  Val. PPL: 111.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:48<00:00, 12.91it/s, train_loss=3.32]\n",
      "100%|██████████| 40/40 [00:00<00:00, 55.84it/s, train_loss=5.04]\n",
      "  0%|          | 1/625 [00:00<01:10,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 49s\n",
      "\tTrain Loss: 3.261 | Train PPL:  26.065\n",
      "\t Val. Loss: 4.589 |  Val. PPL:  98.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:48<00:00, 12.87it/s, train_loss=3.38]\n",
      "100%|██████████| 40/40 [00:00<00:00, 58.01it/s, train_loss=5.01]\n",
      "  0%|          | 1/625 [00:00<01:12,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 49s\n",
      "\tTrain Loss: 3.165 | Train PPL:  23.690\n",
      "\t Val. Loss: 4.524 |  Val. PPL:  92.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:48<00:00, 12.96it/s, train_loss=3.07]\n",
      "100%|██████████| 40/40 [00:00<00:00, 57.70it/s, train_loss=5.1] \n",
      "  0%|          | 1/625 [00:00<01:08,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 48s\n",
      "\tTrain Loss: 3.079 | Train PPL:  21.741\n",
      "\t Val. Loss: 4.615 |  Val. PPL: 101.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:48<00:00, 12.80it/s, train_loss=2.99]\n",
      "100%|██████████| 40/40 [00:00<00:00, 56.89it/s, train_loss=5.06]\n",
      "  0%|          | 1/625 [00:00<01:08,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 49s\n",
      "\tTrain Loss: 2.997 | Train PPL:  20.030\n",
      "\t Val. Loss: 4.510 |  Val. PPL:  90.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:47<00:00, 13.04it/s, train_loss=3.06]\n",
      "100%|██████████| 40/40 [00:00<00:00, 57.14it/s, train_loss=5.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 48s\n",
      "\tTrain Loss: 2.931 | Train PPL:  18.753\n",
      "\t Val. Loss: 4.483 |  Val. PPL:  88.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_step = train(\n",
    "        model,\n",
    "        train_iterator,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        CLIP,\n",
    "        train_step)\n",
    "\n",
    "    valid_loss, val_step = evaluate(\n",
    "        model,\n",
    "        valid_iterator,\n",
    "        criterion,\n",
    "        val_step,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [00:02, 56.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 28944<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557181f83c4640ed8e04d7bf075f6e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210512_153817-2gai4wi5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210512_153817-2gai4wi5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>3.0559</td></tr><tr><td>train_step</td><td>6244</td></tr><tr><td>train_speed(batch/sec)</td><td>12.5405</td></tr><tr><td>_step</td><td>660</td></tr><tr><td>_runtime</td><td>535</td></tr><tr><td>_timestamp</td><td>1620823632</td></tr><tr><td>val_loss</td><td>5.03875</td></tr><tr><td>val_step</td><td>399</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>██▇▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▂▁▂▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_speed(batch/sec)</td><td>█▅▇▇▇▅▅▇▄▅▅▅▆▆▆▁▅▅▆▄▅▄▅▄▃▅▄▄▆▄▆▅▆█▅▆▅▄▅█</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▇▇█▇▆▇█▄▅▆█▄▅▆▇▃▄▅▇▂▃▅▇▂▃▄▇▂▃▅▇▁▃▅▇▁▃▄▇</td></tr><tr><td>val_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">less_hd_2ifqef4p</strong>: <a href=\"https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2gai4wi5\" target=\"_blank\">https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2gai4wi5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model, test_iterator, TRG.vocab, train_step)\n",
    "FINISH = True\n",
    "if FINISH:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: all rooms come with a tv .\n",
      "Generated: each room is fitted with a tv .\n",
      "\n",
      "Original: there is a 24 - hour front desk at the property .\n",
      "Generated: a 24 - hour front desk .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(test_iterator))\n",
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __24__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __22__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __27__ - good score, 70% of points\n",
    "\n",
    "* __29__ - excellent score, 100% of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
