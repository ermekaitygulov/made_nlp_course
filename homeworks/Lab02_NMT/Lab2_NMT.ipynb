{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2: Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github. Loading special files as well\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./utils.py'):\n",
    "    print(\"utils file not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/homeworks/Lab02_NMT/utils.py -nc\n",
    "\n",
    "if not os.path.exists('./my_network.py'):\n",
    "    print(\"network file not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/spring2021/homeworks/Lab02_NMT/my_network.py -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "# TODO check torchtext version\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from contextlib import contextmanager\n",
    "WANDB_GLOBAL = dict(\n",
    "    entity='ermekaitygulov',\n",
    "    group='Baseline',\n",
    "    anonymous='allow',\n",
    "    project='NLP-LAB2',\n",
    "    reinit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def wandb_log(model_name, model_config=None):\n",
    "    try:\n",
    "        model_config = model_config or {}\n",
    "        name = f'{model_name}_{wandb.util.generate_id()}'\n",
    "        run = wandb.init(name=name, config=model_config, **WANDB_GLOBAL)\n",
    "        yield run\n",
    "    finally:\n",
    "        run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9160\n",
      "Unique tokens in target (en) vocabulary: 6654\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '350',\n",
       " 'быстро',\n",
       " 'книги',\n",
       " 'apartman',\n",
       " 'этна',\n",
       " 'ps3',\n",
       " '115',\n",
       " 'каилуа',\n",
       " 'фешенебельном']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '29', 'eastern', 'grab', 'morocco', 'taunus', 'min']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['vegan', ',', 'vegetarian', ',', 'gluten', '-', 'free', ',', 'and', 'dairy', '-', 'free', 'alternatives', 'are', 'also', 'available', 'with', 'prior', 'request', '.'], 'src': ['по', 'предварительному', 'запросу', 'вам', 'подадут', 'вегетарианские', 'блюда', ',', 'блюда', 'безглютеновой', 'диеты', 'и', 'блюда', ',', 'приготовленные', 'без', 'использования', 'молочных', 'продуктов', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in test_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in test_data.examples])\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherepaha/miniconda/envs/py37/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 52x64 (GPU 0)]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 45x64 (GPU 0)]\n",
      "torch.Size([45, 64]) torch.Size([52, 64])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9160, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6654, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (out): Linear(in_features=512, out_features=6654, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,818,302 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# dont forget to put the model to the right device\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, global_step=0, log_window_size=10):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    loss_window = deque(maxlen=log_window_size)\n",
    "    tqdm_iterator = tqdm(iterator)\n",
    "    for i, batch in enumerate(tqdm_iterator):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg        \n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss_window.append(loss.cpu().data.numpy())\n",
    "        if (i+1) % log_window_size==0:\n",
    "            log_dict = dict()\n",
    "            mean_loss = np.mean(loss_window)\n",
    "            log_dict['train_loss'] = mean_loss\n",
    "            log_dict['train_step'] = global_step\n",
    "            if tqdm_iterator._ema_dt():\n",
    "                log_dict['train_speed(batch/sec)'] = tqdm_iterator._ema_dn()/ tqdm_iterator._ema_dt()\n",
    "            wandb.log(log_dict)\n",
    "            tqdm_iterator.set_postfix(train_loss = mean_loss)\n",
    "            \n",
    "        global_step += 1\n",
    "        \n",
    "    return epoch_loss / len(iterator), global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, global_step=0, log_window_size=10):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    loss_window = deque(maxlen=log_window_size)\n",
    "    tqdm_iterator = tqdm(iterator)\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(tqdm_iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            loss_window.append(loss.item())\n",
    "            \n",
    "            if (i+1) % log_window_size==0:\n",
    "                log_dict = dict()\n",
    "                mean_loss = np.mean(loss_window)\n",
    "                log_dict['val_loss'] = mean_loss\n",
    "                log_dict['val_step'] = global_step\n",
    "                wandb.log(log_dict)\n",
    "                tqdm_iterator.set_postfix(train_loss = mean_loss)\n",
    "            \n",
    "            global_step += 1\n",
    "        \n",
    "    return epoch_loss / len(iterator), global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29680<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210506_192350-vg4knfe7/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210506_192350-vg4knfe7/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>4.42328</td></tr><tr><td>train_step</td><td>619</td></tr><tr><td>train_speed(batch/sec)</td><td>7.68775</td></tr><tr><td>_step</td><td>65</td></tr><tr><td>_runtime</td><td>87</td></tr><tr><td>_timestamp</td><td>1620318317</td></tr><tr><td>val_loss</td><td>5.55581</td></tr><tr><td>val_step</td><td>39</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_speed(batch/sec)</td><td>▃▁▅▃▃▄▄▄▄▇▄▄▄▆▆▃▆▄▄▄▄▃▆▆▅█▅▅▃▅▃▆▄▄▆▃▃▃▄▃</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>▁▅▆█</td></tr><tr><td>val_step</td><td>▁▃▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">test_3v6gs81o</strong>: <a href=\"https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/vg4knfe7\" target=\"_blank\">https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/vg4knfe7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">test_2etx9kxo</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ermekaitygulov/NLP-LAB2\" target=\"_blank\">https://wandb.ai/ermekaitygulov/NLP-LAB2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2y2maqrw\" target=\"_blank\">https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2y2maqrw</a><br/>\n",
       "                Run data is saved locally in <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210506_192539-2y2maqrw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2y2maqrw)</h1><p></p><iframe src=\"https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2y2maqrw\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb22f62cb00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "train_step = 0\n",
    "val_step = 0\n",
    "best_valid_loss = float('inf')\n",
    "model_name = 'test'\n",
    "model_config = {}\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "name = f'{model_name}_{wandb.util.generate_id()}'\n",
    "if wandb.run:\n",
    "    wandb.finish()\n",
    "wandb.init(name=name, config=model_config, **WANDB_GLOBAL)\n",
    "wandb.watch(model, criterion, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [01:18<00:00,  7.95it/s, train_loss=4.32]\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.11it/s, train_loss=5.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 19s\n",
      "\tTrain Loss: 4.967 | Train PPL: 143.603\n",
      "\t Val. Loss: 5.118 |  Val. PPL: 167.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_step = train(\n",
    "        model,\n",
    "        train_iterator,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        CLIP,\n",
    "        train_step)\n",
    "\n",
    "    valid_loss, val_step = evaluate(\n",
    "        model,\n",
    "        valid_iterator,\n",
    "        criterion,\n",
    "        val_step,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29838<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210506_192539-2y2maqrw/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/cherepaha/Projects/made/2sem/made_nlp_course/homeworks/Lab02_NMT/wandb/run-20210506_192539-2y2maqrw/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>4.31892</td></tr><tr><td>train_step</td><td>619</td></tr><tr><td>train_speed(batch/sec)</td><td>7.96099</td></tr><tr><td>_step</td><td>65</td></tr><tr><td>_runtime</td><td>81</td></tr><tr><td>_timestamp</td><td>1620318420</td></tr><tr><td>val_loss</td><td>5.61769</td></tr><tr><td>val_step</td><td>39</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>█▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>train_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_speed(batch/sec)</td><td>▄▃▄▄▆▄▅▄█▅▇▅▆▂▅▂▄▅█▁▆▅▃▆▆▂▅▆▅▇▆▆▆▅▅▇▇▅▅▅</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>▁▅▇█</td></tr><tr><td>val_step</td><td>▁▃▆█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">test_2etx9kxo</strong>: <a href=\"https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2y2maqrw\" target=\"_blank\">https://wandb.ai/ermekaitygulov/NLP-LAB2/runs/2y2maqrw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FINISH = True\n",
    "if FINISH:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: all units are functionally furnished .\n",
      "Generated: rooms with a .\n",
      "\n",
      "Original: guests enjoy free parking .\n",
      "Generated: free parking .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [00:02, 40.96it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.017227533948315"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __24__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __22__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __27__ - good score, 70% of points\n",
    "\n",
    "* __29__ - excellent score, 100% of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', '24', '-', 'hour', 'front', 'desk', '.']\n",
      "['you', 'will', 'find', 'a', '24', '-', 'hour', 'front', 'desk', 'at', 'the', 'property', '.']\n"
     ]
    }
   ],
   "source": [
    "i = 80\n",
    "print(generated_text[i])\n",
    "print(original_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
