data:
  train_size: 0.8
  val_size: 0.15
  test_size: 0.05
  batch_size: 64
  path: '../../datasets/Machine_translation_EN_RU/data.txt'
  word_min_freq: 5
pretrain:
  epoch: 0
  opt_class: Adam
  scheduler_class: CosineAnnealingWarmRestarts
  scheduler_params:
    T_0: 625
    T_mult: 2
  grad_clip: 1
train:
  epoch: 0
  opt_class: Adam
  scheduler_class: CosineAnnealingWarmRestarts
  scheduler_params:
    T_0: 625
    T_mult: 2
  grad_clip: 1
  teacher_enforce:
    ratio_start: 0.0
    ratio_growth: 0.1
    ratio_max: 0.7
sgd_train:
  epoch: 0
  opt_class: SGD
  opt_params:
    lr: 0.0001
    momentum: 0.9
    nesterov: True
  scheduler_class: CosineAnnealingWarmRestarts
  scheduler_params:
    T_0: 2500
    T_mult: 2
  grad_clip: 1
  teacher_enforce:
    ratio_start: 0.5
    ratio_growth: 0.1
    ratio_max: 0.8
model_path: 'model_save/pretrain_baseline_ogo7yye5/main_stage-model.pt'
model:
  name: hybrid
  params:
    emb_dim: &emb_dim 512
    encoder:
      layer_number: 3
      nhead: 8
    decoder:
      emb_dim: *emb_dim
      dropout: 0.5
      hid_dim: *emb_dim
      n_layers: 1
#    hid_dim: &hid_dim 256
#    n_layers: &n_layers 2
#    teacher_forcing_ratio: 0
#    encoder:
#      emb_dim: 512
#      dropout: 0.5
#      hid_dim: *hid_dim
#      n_layers: *n_layers
#    decoder:
#      emb_dim: 512
#      dropout: 0.5
#      hid_dim: *hid_dim
#      n_layers: *n_layers
