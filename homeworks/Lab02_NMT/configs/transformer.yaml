src_bpe: 'configs/ru_bpe_2000'
trg_bpe: 'configs/en_bpe_2000'
data:
  train_size: 0.8
  val_size: 0.15
  test_size: 0.05
  batch_size: 64
  path: '../../datasets/Machine_translation_EN_RU/data.txt'
  word_min_freq: 1
pretrain:
  epoch: 0
  opt_class: Adam
  scheduler_class: CosineAnnealingWarmRestarts
  scheduler_params:
    T_0: 625
    T_mult: 2
  grad_clip: 1
train:
  epoch: 15
  opt_class: Adam
  scheduler_class: OneCycleLR
  scheduler_params:
    max_lr: 0.001
    steps_per_epoch: 625
    epochs: 15
  grad_clip: 1
  teacher_enforce:
    ratio_start: 0.0
    ratio_growth: 0.1
    ratio_max: 0.3
sgd_train:
  epoch: 0
  opt_class: SGD
  opt_params:
    lr: 0.0001
    momentum: 0.9
    nesterov: True
  scheduler_class: CosineAnnealingWarmRestarts
  scheduler_params:
    T_0: 2500
    T_mult: 2
  grad_clip: 1
  teacher_enforce:
    ratio_start: 0.5
    ratio_growth: 0.1
    ratio_max: 0.8
#model_path: 'model_save/bpe_1dkgbjzx/main_stage-model.pt'
model:
  name: transformer
  params:
    teacher_forcing_prob: 0.5
    emb_dim: 256
    encoder:
      layer_number: 4
      dim_feedforward: 256
      dropout: 0.2
      nhead: 4
    decoder:
      layer_number: 4
      dim_feedforward: 256
      dropout: 0.2
      nhead: 4
    pos_encoder:
      dropout: 0.1
