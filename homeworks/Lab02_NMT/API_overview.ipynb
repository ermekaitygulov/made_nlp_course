{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import add_to_catalog\n",
    "from experiment import EXPERIMENT_CATALOG\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства разработки была сделана попытка сделать как можно более гибкий шаблон экспериментов. Конечно без костылей не обошлось, однако шаблон сильно упростил расширение библиотеки экспериментов.\n",
    "Шаблон включает в себя несколько похожих этапов:\n",
    "* чтение данных\n",
    "* инициализация моделей\n",
    "* инициализация оптимизатора и т.д.\n",
    "\n",
    "Т.к. в данной лабораторной работе все эксперименты проходили с одним и тем же датасетом, получилось добавлять новые эксперименты не путем наследования базового класса, а с помощью интерфейса Train_stage (идейно это общий интерфейс, на практике интерфейс+изолента :D). Т.е. создавались новые Stage'ы и компоновались с помощью ComposeStage, где прогонялись последовательно.\n",
    "\n",
    "Для логирования использовалась библиотека wandb. Если был запущен где-то wandb.init(), то графики будут логироваться, иначе будет принтится основной лосс на трейне и валидации. Также модели сохраняются в папку с именем run'а из wandb, что может быть достаточно удобным. Так же в папку run'а сохранялся конфиг + мета информация (скорость инференса, время обучения, блеу)  \n",
    "\n",
    "![scheme](image/experiment.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline': <class 'experiment.baseline.Baseline'>,\n",
      " 'bpe': <class 'experiment.bpe.Baseline'>,\n",
      " 'pretrain_baseline': <class 'experiment.baseline.Baseline'>,\n",
      " 'scst': <class 'experiment.scst.SelfCriticalSeqTrain'>}\n"
     ]
    }
   ],
   "source": [
    "pprint(EXPERIMENT_CATALOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'batch_size': 64,\n",
      "          'path': '../../datasets/Machine_translation_EN_RU/data.txt',\n",
      "          'test_size': 0.05,\n",
      "          'train_size': 0.8,\n",
      "          'val_size': 0.15,\n",
      "          'word_min_freq': 5},\n",
      " 'model': {'name': 'lstm_teacher',\n",
      "           'params': {'decoder': {'dropout': 0.2,\n",
      "                                  'emb_dim': 512,\n",
      "                                  'hid_dim': 512,\n",
      "                                  'n_layers': 2},\n",
      "                      'encoder': {'dropout': 0.2,\n",
      "                                  'emb_dim': 512,\n",
      "                                  'hid_dim': 512,\n",
      "                                  'n_layers': 2},\n",
      "                      'hid_dim': 512,\n",
      "                      'n_layers': 2,\n",
      "                      'teacher_forcing_ratio': 0}},\n",
      " 'model_path': 'model_save/pretrain_baseline_2jxtl023/final-model.pt',\n",
      " 'pretrain': {'epoch': 5,\n",
      "              'grad_clip': 1,\n",
      "              'opt_class': 'Adam',\n",
      "              'scheduler_class': 'OneCycleLR',\n",
      "              'scheduler_params': {'epochs': 5,\n",
      "                                   'max_lr': 0.001,\n",
      "                                   'steps_per_epoch': 2649}},\n",
      " 'scst': {'entropy_weight': 0.001,\n",
      "          'epoch': 5,\n",
      "          'grad_clip': 1,\n",
      "          'opt_class': 'Adam',\n",
      "          'opt_params': {'lr': 0.0001}},\n",
      " 'train': {'epoch': 15,\n",
      "           'grad_clip': 1,\n",
      "           'opt_class': 'Adam',\n",
      "           'scheduler_class': 'OneCycleLR',\n",
      "           'scheduler_params': {'epochs': 15,\n",
      "                                'max_lr': 0.001,\n",
      "                                'steps_per_epoch': 2649},\n",
      "           'teacher_enforce': {'ratio_growth': 0.1,\n",
      "                               'ratio_max': 0.5,\n",
      "                               'ratio_start': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "config_path = 'configs/scst.yaml'\n",
    "with open(config_path) as fin:\n",
    "    config = yaml.load(fin)\n",
    "    \n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конфиг к каждом стэйджу подтягивается по имени стэйджа. В каждом стэйдже свой оптимизатор и скедулер. Какой оптимизатор или скедулер будет использован можно контролировать через конфиг.\n",
    "\n",
    "То же самое с моделью. С помощью декоратора utils.add_to_catalog модели добавлялись в словарь, который используется в Experiment классе при ините модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MOD = True\n",
    "if TEST_MOD:\n",
    "    config['data']['path'] = 'test_data.txt'\n",
    "    config.pop('model_path')\n",
    "experiment_name = 'scst'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "experiment = EXPERIMENT_CATALOG[experiment_name](config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 47.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 285.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 514.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 524.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 528.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 516.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 2.891 | Train PPL:  18.010\n",
      "\t Val. Loss: 2.900 |  Val. PPL:  18.170 |  BLEU: 0.000\n",
      "Epoch: 02\n",
      "\tTrain Loss: 2.886 | Train PPL:  17.929\n",
      "\t Val. Loss: 2.900 |  Val. PPL:  18.170 |  BLEU: 0.000\n",
      "Epoch: 03\n",
      "\tTrain Loss: 2.882 | Train PPL:  17.854\n",
      "\t Val. Loss: 2.900 |  Val. PPL:  18.170 |  BLEU: 0.000\n",
      "Epoch: 04\n",
      "\tTrain Loss: 2.875 | Train PPL:  17.728\n",
      "\t Val. Loss: 2.900 |  Val. PPL:  18.169 |  BLEU: 0.000\n",
      "Epoch: 05\n",
      "\tTrain Loss: 2.871 | Train PPL:  17.655\n",
      "\t Val. Loss: 2.900 |  Val. PPL:  18.169 |  BLEU: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.23it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 3.056 | Train PPL:  21.250\n",
      "\t Val. Loss: 3.032 |  Val. PPL:  20.739 |  BLEU: 0.000\n",
      "Epoch: 02\n",
      "\tTrain Loss: 3.050 | Train PPL:  21.107\n",
      "\t Val. Loss: 3.033 |  Val. PPL:  20.765 |  BLEU: 0.000\n",
      "Epoch: 03\n",
      "\tTrain Loss: 3.043 | Train PPL:  20.965\n",
      "\t Val. Loss: 3.036 |  Val. PPL:  20.821 |  BLEU: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.05it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04\n",
      "\tTrain Loss: 3.035 | Train PPL:  20.802\n",
      "\t Val. Loss: 3.040 |  Val. PPL:  20.904 |  BLEU: 0.000\n",
      "Epoch: 05\n",
      "\tTrain Loss: 3.029 | Train PPL:  20.673\n",
      "\t Val. Loss: 3.044 |  Val. PPL:  20.985 |  BLEU: 0.000\n",
      "Epoch: 06\n",
      "\tTrain Loss: 3.021 | Train PPL:  20.521\n",
      "\t Val. Loss: 3.039 |  Val. PPL:  20.887 |  BLEU: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.07it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07\n",
      "\tTrain Loss: 3.015 | Train PPL:  20.384\n",
      "\t Val. Loss: 3.041 |  Val. PPL:  20.920 |  BLEU: 0.000\n",
      "Epoch: 08\n",
      "\tTrain Loss: 3.006 | Train PPL:  20.213\n",
      "\t Val. Loss: 3.042 |  Val. PPL:  20.955 |  BLEU: 0.000\n",
      "Epoch: 09\n",
      "\tTrain Loss: 2.999 | Train PPL:  20.059\n",
      "\t Val. Loss: 3.044 |  Val. PPL:  20.992 |  BLEU: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 30.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.30it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Loss: 2.990 | Train PPL:  19.896\n",
      "\t Val. Loss: 3.046 |  Val. PPL:  21.033 |  BLEU: 0.000\n",
      "Epoch: 11\n",
      "\tTrain Loss: 2.981 | Train PPL:  19.707\n",
      "\t Val. Loss: 3.048 |  Val. PPL:  21.077 |  BLEU: 0.000\n",
      "Epoch: 12\n",
      "\tTrain Loss: 2.972 | Train PPL:  19.528\n",
      "\t Val. Loss: 3.050 |  Val. PPL:  21.125 |  BLEU: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 31.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.62it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "\tTrain Loss: 2.963 | Train PPL:  19.348\n",
      "\t Val. Loss: 3.053 |  Val. PPL:  21.179 |  BLEU: 0.000\n",
      "Epoch: 14\n",
      "\tTrain Loss: 2.951 | Train PPL:  19.122\n",
      "\t Val. Loss: 3.056 |  Val. PPL:  21.238 |  BLEU: 0.000\n",
      "Epoch: 15\n",
      "\tTrain Loss: 2.939 | Train PPL:  18.893\n",
      "\t Val. Loss: 3.059 |  Val. PPL:  21.303 |  BLEU: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.42it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tVal BLEU: 0.000\n",
      "Epoch: 02\n",
      "\tVal BLEU: 0.000\n",
      "Epoch: 03\n",
      "\tVal BLEU: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04\n",
      "\tVal BLEU: 0.000\n",
      "Epoch: 05\n",
      "\tVal BLEU: 0.000\n"
     ]
    }
   ],
   "source": [
    "experiment.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 61.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
